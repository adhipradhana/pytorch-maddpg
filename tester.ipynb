{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Battle Royale Environment Trainer\n",
    "This notebook is for training Battle Royale agents. MADDPG is used for training the agents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Environment Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from gym_unity.envs import UnityEnv\n",
    "\n",
    "print(\"Python version:\")\n",
    "print(sys.version)\n",
    "print(sys.executable)\n",
    "\n",
    "# check Python version\n",
    "if (sys.version_info[0] < 3):\n",
    "    raise Exception(\"ERROR: ML-Agents Toolkit (v0.3 onwards) requires Python 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment name\n",
    "# Remember to put battle royale environment configuration within the config folder\n",
    "env_name = \"environment/battle-royale-static\"\n",
    "\n",
    "env = UnityEnv(env_name, worker_id=3, use_visual=False, multiagent=True)\n",
    "\n",
    "print(str(env))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 6272727\n",
    "n_states = env.observation_space.shape[0]\n",
    "n_actions = env.action_space.shape[0]\n",
    "n_agents = env.number_agents\n",
    "n_episode = 50\n",
    "max_steps = 2000\n",
    "buffer_capacity = 1000000\n",
    "batch_size = 1000\n",
    "episodes_before_train = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup seed\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "maddpg = MADDPG(n_agents, n_states, n_actions, batch_size, buffer_capacity, episodes_before_train)\n",
    "\n",
    "FloatTensor = torch.cuda.FloatTensor if maddpg.use_cuda else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path = os.path.join(os.getcwd(), 'checkpoint', 'Time_2020-03-25_08-42-13.632845_NAgent_2', 'Time_2020-03-25_08-42-13.632845_NAgent_2_Episode_180.pth')\n",
    "maddpg.load(path, map_location='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing model...\")\n",
    "for i_episode in range(n_episode):\n",
    "    # reset environment\n",
    "    obs = env.reset()\n",
    "    obs = np.stack(obs)\n",
    "    \n",
    "    # convert observation to tensor\n",
    "    if isinstance(obs, np.ndarray):\n",
    "        obs = torch.from_numpy(obs).float()\n",
    "    \n",
    "    total_reward = 0.0\n",
    "    for i_step in range(max_steps):\n",
    "        obs = obs.type(FloatTensor)\n",
    "        actions = maddpg.select_action(obs).data.cpu()\n",
    "        actions_list = actions.tolist()\n",
    "        \n",
    "        obs_, reward, done, _ = env.step(actions_list)\n",
    "        \n",
    "        reward = torch.FloatTensor(reward).type(FloatTensor)\n",
    "        obs_ = np.stack(obs_)\n",
    "        obs_ = torch.from_numpy(obs_).float()\n",
    "        if i_step != max_steps - 1:\n",
    "            next_obs = obs_\n",
    "        else:\n",
    "            next_obs = None\n",
    "\n",
    "        total_reward += reward.sum()     \n",
    "        obs = next_obs\n",
    "\n",
    "        # check if done\n",
    "        if True in done:\n",
    "            break\n",
    "\n",
    "    maddpg.episode_done += 1\n",
    "    print(\"Episode: {}, reward = {}\".format(i_episode, total_reward))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Close Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unity-battle-royale",
   "language": "python",
   "name": "unity-battle-royale"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
